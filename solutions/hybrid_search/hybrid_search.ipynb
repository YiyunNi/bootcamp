{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search\n",
    "In this example we are going to show how to do a hybrid query combining the vector database Milvus and the relational database Postgres. A hybrid query allows you to search based on many parameters and is useful for situations where you have to narrow down your results. In the future, Milvus 2.0 will allow you to perform this type of searching without having to use a secondary relational database. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "In this example we are using randomly generated data. We do this because we are mainly trying to demonstrate the flow of doing a hybrid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "| Python Packages | Docker Servers |\n",
    "| --------------- | -------------- |\n",
    "| pymilvus        | Milvus-1.1.0   |\n",
    "| numpy           | Postgres          |\n",
    "|  psycopg2 |\n",
    "|  faker |\n",
    "\n",
    "We have included a `requirements.txt` file in order to easily satisfy the required packages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up and Running\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install Packages\n",
    "Install the required python packages. If you are on mac and recieve an error downloading psycopg2, please first install postgresql with brew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymilvus==1.1.0 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: numpy in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.20.2)\n",
      "Requirement already satisfied: psycopg2-binary in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (2.8.6)\n",
      "Requirement already satisfied: psycopg2 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (2.8.6)\n",
      "Requirement already satisfied: faker in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (8.1.4)\n",
      "Requirement already satisfied: gdown in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (3.13.0)\n",
      "Requirement already satisfied: requests>=2.22.0 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from pymilvus==1.1.0->-r requirements.txt (line 1)) (2.25.1)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from pymilvus==1.1.0->-r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: grpcio-tools>=1.22.0 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from pymilvus==1.1.0->-r requirements.txt (line 1)) (1.37.0)\n",
      "Requirement already satisfied: grpcio>=1.22.0 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from pymilvus==1.1.0->-r requirements.txt (line 1)) (1.37.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from grpcio>=1.22.0->pymilvus==1.1.0->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from grpcio-tools>=1.22.0->pymilvus==1.1.0->-r requirements.txt (line 1)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.5.0.post1 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from grpcio-tools>=1.22.0->pymilvus==1.1.0->-r requirements.txt (line 1)) (3.15.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from requests>=2.22.0->pymilvus==1.1.0->-r requirements.txt (line 1)) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from requests>=2.22.0->pymilvus==1.1.0->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from requests>=2.22.0->pymilvus==1.1.0->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from requests>=2.22.0->pymilvus==1.1.0->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: text-unidecode==1.3 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from faker->-r requirements.txt (line 5)) (1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from faker->-r requirements.txt (line 5)) (2.8.1)\n",
      "Requirement already satisfied: filelock in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from gdown->-r requirements.txt (line 6)) (3.0.12)\n",
      "Requirement already satisfied: tqdm in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from gdown->-r requirements.txt (line 6)) (4.60.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/filiphaltmayer/opt/miniconda3/envs/coinbase_demo/lib/python3.8/site-packages (from requests>=2.22.0->pymilvus==1.1.0->-r requirements.txt (line 1)) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "# ! brew install postgresql\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Milvus Server\n",
    "\n",
    "This demo uses Milvus 1.1.0, please refer to the [Install Milvus](https://milvus.io/docs/v1.1.0/install_milvus.md) guide to learn how to use this docker container. For this example we wont be mapping any local volumes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b7707c1a705f8196a32f0cb60d2860e52e6d6346fa206e97548b7429b0cb52d8\n"
     ]
    }
   ],
   "source": [
    "! docker run -d \\\n",
    "-p 19532:19530 \\\n",
    "-p 19122:19121 \\\n",
    "milvusdb/milvus:1.1.0-cpu-d050721-5e559c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Postgres Server\n",
    "For now, Milvus doesn't support storing multiple attributes for the data. Because of this we have to use another service to store these attributes and search through them, in this case PostgreSQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6f891cbaaba280a41ad3b6606513c941f77c5396a260405539d93828bb538378\n"
     ]
    }
   ],
   "source": [
    "! docker run  -d  -p 5432:5432 -e POSTGRES_HOST_AUTH_METHOD=trust postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Servers\n",
    "We first start off by connecting to the servers. In this case they are all docker containers and are running on localhost with their default ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connectings to Milvus and Postgres\n",
    "\n",
    "import milvus\n",
    "import psycopg2\n",
    "\n",
    "milv = milvus.Milvus(host='localhost', port='19532')\n",
    "conn = psycopg2.connect(host='localhost', port='5432', user='postgres', password='postgres')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Collection \n",
    "\n",
    "The next step is to create the collection in Milvus in order to store the vectors. We need to specify the parameters `collection_name`, `dimension`, `index_file_size`, and `metric_type` when creating it. In this case we are storing 128-dimensional vectors and using the Euclidean distance. Our data segments are also set to the default 1024MB. \n",
    "\n",
    "In this case we are also deleting the collection so that we have a fresh start each time this notebook is loaded up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status(code=0, message='Create collection successfully!')\n"
     ]
    }
   ],
   "source": [
    "collection_name = 'hybrid_search'\n",
    "VEC_DIM = 128\n",
    "\n",
    "milv.drop_collection(collection_name)\n",
    "\n",
    "param = {\n",
    "            'collection_name': collection_name,\n",
    "            'dimension': VEC_DIM,\n",
    "            'index_file_size':1024,\n",
    "            'metric_type':MetricType.L2\n",
    "        }\n",
    "status, ok = milv.has_collection(collection_name)\n",
    "\n",
    "if not ok:\n",
    "    status = milv.create_collection(param)\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Index\n",
    "Currently, a collection only supports one index type. In this case we are using the ivf_sq8 index. Since this index is an ivf index, we must provide the parameter `nlist`. This parameter tells milvus how many clusters to make in each index file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(collection_name='hybrid_search', index_type=<IndexType: IVF_SQ8>, params={'nlist': 16384})\n"
     ]
    }
   ],
   "source": [
    "index_param = {\n",
    "    'nlist': 16384\n",
    "}\n",
    "status = milv.create_index(collection_name, IndexType.IVF_SQ8, index_param)\n",
    "status, index = milv.get_index_info(collection_name)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the table in Postgres  \n",
    "PostgreSQL will be used to store the Milvus ID and its corresponding attributes. Here is a description of the attributes:\n",
    "- `sex`:\t   Define the sex of the human: male or female.\n",
    "- `age`:\t Specifies the age of the human: 1-99\n",
    "- `has_glasses`: \tDefines if the human face wears glasses: True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pg_table(conn,cursor,table_name):\n",
    "    try:       \n",
    "        sql = \"CREATE TABLE \" + table_name + \" (ids bigint, sex char(10), age smallint, has_glasses boolean);\"\n",
    "        cursor.execute(sql)\n",
    "        conn.commit()\n",
    "        print(\"Created postgres table!\")\n",
    "    except:\n",
    "        print(\"Can't create postgres table.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Before creating the table we are clearing any existing tables. This is done in order to have a clean run each time when loading this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created postgres table!\n"
     ]
    }
   ],
   "source": [
    "table_name ='hybrid_search'\n",
    "drop_table = \"DROP TABLE IF EXISTS \" + table_name\n",
    "\n",
    "cursor.execute(drop_table)\n",
    "conn.commit()\n",
    "\n",
    "create_pg_table(conn, cursor, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and Store Data\n",
    "For this example we are going to be using randomly generated data to simulate a users situation. We are going to randomly assign sex, age, and if they wear glasses to randomly generated vectors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Generate Embeddings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_data(amount):\n",
    "    embed = np.random.rand(amount, VEC_DIM).astype('float32')\n",
    "    return embed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Store Data by ID in Postgres\n",
    "For this example we are loading in the IDs and attributes through chunks. For each chunk, we write to a .csv file and then write that csv file to the Postgres server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "import os\n",
    "fake = Faker()\n",
    "\n",
    "def record_txt(ids,fname):\n",
    "    with open(fname,'w+') as f:\n",
    "        for i in range(len(ids)):\n",
    "            sex = random.choice(['female','male'])\n",
    "            age = random.randint(1,99)\n",
    "            has_glasses = random.choice(['True','False'])\n",
    "            line = str(ids[i]) + \"|\" + sex + \"|\" + str(age) + \"|\" + str(has_glasses) + \"\\n\"\n",
    "            f.write(line)\n",
    "            \n",
    "def copy_data_to_pg(conn, cursor,fname ,table_name):\n",
    "    fname = os.path.join(os.getcwd(),fname)\n",
    "    try:\n",
    "        sql = \"COPY \" + table_name + \" FROM STDIN DELIMITER '|' CSV HEADER\"\n",
    "        cursor.copy_expert(sql, open(fname, \"r\"))\n",
    "        conn.commit()\n",
    "        \n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(\"copy data to postgres failed: \", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Insert into Milvus and Postgres\n",
    "When inserting the data into Milvus and Postgres, we push the vectors by chunks of size `BASE_LEN`. Milvus and Postgres perform better when doing batch inserts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert Step: 1/10\n",
      "Insert Step: 2/10\n",
      "Insert Step: 3/10\n",
      "Insert Step: 4/10\n",
      "Insert Step: 5/10\n",
      "Insert Step: 6/10\n",
      "Insert Step: 7/10\n",
      "Insert Step: 8/10\n",
      "Insert Step: 9/10\n",
      "Insert Step: 10/10\n"
     ]
    }
   ],
   "source": [
    "filen = 't.csv'\n",
    "VEC_NUM = 10000\n",
    "BASE_LEN = 1000\n",
    "count = 0\n",
    "while count < (VEC_NUM // BASE_LEN):\n",
    "    vectors = generate_data(BASE_LEN)\n",
    "    vectors_ids = [id for id in range(count*BASE_LEN,(count+1)*BASE_LEN)]\n",
    "    status, ids = milv.insert(collection_name=collection_name, records=vectors, ids=vectors_ids)\n",
    "    record_txt(ids,filen)\n",
    "    copy_data_to_pg(conn, cursor,filen ,pg_name)\n",
    "    count =count + 1\n",
    "    print(\"Insert Step: \" + str(count) + \"/\" + str(int(VEC_NUM/BASE_LEN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Search\n",
    "Once we have the data all loaded up, we can finally then perform the searches. We begin by first creating a vector to search for. With this vector we first search through Milvues to find the closest vector IDs. We then combine these IDs with the attributes being searched for in order to perform the search in the Postgres server. In this example we are searching the closest vectors that match `sex`, `has_glasses`, and is under `age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 10\n",
    "_param = {'nprobe': 64}\n",
    "\n",
    "def search_in_milvus(vector, milvus_connection):\n",
    "    status, results = milvus_connection.search(collection_name = collection_name,query_records=vector, top_k=TOP_K, params=_param)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_pg(conn,cursor,result_ids,result_distance,sex,age,glasses):\n",
    "    ids = str(result_ids[0])\n",
    "    i = 1\n",
    "    while i < len(result_ids):\n",
    "        ids = ids + \",\" + str(result_ids[i])\n",
    "        i = i + 1\n",
    "    sql = \"select * from \" + table_name + \" where ids in (\" + ids + \")\" + \"and age <=\" + str(age) + \" and sex='\" + sex + \"' and has_glasses='\" + str(glasses) + \"';\"\n",
    "\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        rows=cursor.fetchall()\n",
    "        return rows\n",
    "    except Exception as e:\n",
    "        print(\"search failed!:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are querying 4 random vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = generate_data(4)\n",
    "milvus_results = search_in_milvus(query_vec, milv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After recieving the results from Milvus, we then have to pull out the IDs and Distances from the result in order to search the Postgres server. Finally, all the values are bundled up for each query vector under `hybrid_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = \"male\"\n",
    "glasses = \"True\"\n",
    "age = 64\n",
    "\n",
    "\n",
    "hybrid_results = []\n",
    "\n",
    "for single_query in milvus_results:\n",
    "    result_ids, result_distances = [], []\n",
    "    for result_vector in single_query:\n",
    "        result_ids.append(result_vector.id)\n",
    "        result_distances.append(result_vector.distance)\n",
    "        \n",
    "    sql_results = search_in_pg(conn, cursor, result_ids, result_distances, sex, age, glasses)\n",
    "    hybrid_results.append((result_ids, result_distances, sql_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Results\n",
    "Once we have all the results the only step left is to print out all the results. In this case we order all the results by distance before printing out the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_rows_distance(full_results):\n",
    "    \n",
    "    rows = full_results[2]\n",
    "    distance = full_results[1]\n",
    "    ids = full_results[0]\n",
    "    \n",
    "    new_results = []\n",
    "    if len(rows)>0:\n",
    "        for row in rows:\n",
    "            index_flag = ids.index(row[0])\n",
    "            temp = [row[0]] + list(row[1:5]) + [distance[index_flag]]\n",
    "            new_results.append(temp)\n",
    "            \n",
    "        new_results = np.array(new_results)\n",
    "        sort_arg = np.argsort(new_results[:,4])\n",
    "        new_results = new_results[sort_arg].tolist()\n",
    "        columns = [\"ids:\", \"sex:\", \"age:\", \"has_glasses:\", \"distance:\"]\n",
    "        \n",
    "        new_results.insert(0, columns)\n",
    "        \n",
    "        col_width = max(len(word) for row in new_results for word in row) + 2  # padding\n",
    "        for row in new_results:\n",
    "            print(\"\".join(word.ljust(col_width) for word in row))\n",
    "        \n",
    "    else:\n",
    "        print(\"no result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 0\n",
      "ids:                sex:                age:                has_glasses:        distance:           \n",
      "82                  male                8                   True                14.634078979492188  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Query: 1\n",
      "ids:                sex:                age:                has_glasses:        distance:           \n",
      "3188                male                60                  True                14.761774063110352  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Query: 2\n",
      "ids:                sex:                age:                has_glasses:        distance:           \n",
      "526                 male                42                  True                15.69881820678711   \n",
      "9787                male                50                  True                15.713668823242188  \n",
      "9343                male                35                  True                15.880270004272461  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Query: 3\n",
      "ids:               sex:               age:               has_glasses:       distance:          \n",
      "1532               male               17                 True               13.26909065246582  \n",
      "8239               male               53                 True               14.92601203918457  \n",
      "2719               male               33                 True               14.94442367553711  \n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(hybrid_results)):\n",
    "    print(\"Query: \" + str(x))\n",
    "    merge_rows_distance(hybrid_results[x])\n",
    "    print(\"-\"*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
